# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B-9BMzB2D3fWpwhFe9MLpxSo9vLJaUzv
"""

import os
from typing import Sequence

from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_community.document_loaders import PyPDFLoader
from langchain_core.messages import AIMessage, BaseMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.vectorstores import InMemoryVectorStore
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import START, StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from typing_extensions import Annotated, TypedDict
from langchain.tools.retriever import create_retriever_tool
from langchain_community.llms import HuggingFaceEndpoint
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_groq import ChatGroq

llm = ChatGroq(model="llama-3.3-70b-versatile")

tool = TavilySearchResults(max_results=2)
tools = [tool]

from langchain_core.tools import tool

memory = MemorySaver()

from langgraph.prebuilt import create_react_agent

system_prompt="""Use constructivist theory of learning to teach the topic the user gives you. 
Build gradually on the user understanding of the topic, do not cognitively overload the user with information. 
Output short and directed outputs to guide the user to form an understanding of the topic on his own. 
"""

graph1 = create_react_agent(llm, tools=[], checkpointer=memory, state_modifier=system_prompt)


def ask_question(messages): # Modified to take messages as input
    """Asks a question to the LangGraph agent and returns the response."""
    try:
        result = graph1.invoke(
            {"messages": messages},
            config={"thread_id": "1"},
        )
        return result["messages"][-1].content
    except Exception as e:
        print(f"LangGraph Error: {e}")
        return "I encountered an error while processing your request."